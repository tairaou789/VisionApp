{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3ec59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-vision-computervision\n",
      "  Downloading azure_cognitiveservices_vision_computervision-0.9.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting azure-common~=1.1\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting msrest>=0.5.0\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2021.10.8)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\anaconda\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.26.0)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, isodate, msrest, azure-common, azure-cognitiveservices-vision-computervision\n",
      "Successfully installed azure-cognitiveservices-vision-computervision-0.9.0 azure-common-1.1.28 isodate-0.6.1 msrest-0.6.21 oauthlib-3.2.0 requests-oauthlib-1.3.1\n",
      "Requirement already satisfied: pillow in c:\\anaconda\\lib\\site-packages (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade azure-cognitiveservices-vision-computervision\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f7649d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcfa68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secret.json') as f:\n",
    "    secret = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db7454c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = secret['KEY']\n",
    "ENDPOINT = secret['ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3752ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "computervision_client = ComputerVisionClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c106dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3dc88dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'an ancient city with many ruins with Colosseum in the background' with confidence 33.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API\n",
    "description_results = computervision_client.describe_image(remote_image_url )\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4930000",
   "metadata": {},
   "source": [
    "## 画像カテゴリの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "487928fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Categorize an image - remote =====\n",
      "Categories from remote image: \n",
      "'building_' with confidence 31.64%\n",
      "'others_' with confidence 0.39%\n",
      "'outdoor_' with confidence 3.91%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Categorize an image - remote =====\")\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"categories\"]\n",
    "# Call API with URL and features\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc29f12",
   "metadata": {},
   "source": [
    "## 画像タグの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1faf22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "889afa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - remote =====\n",
      "Detecting objects in remote image:\n",
      "object at location 213, 365, 85, 208\n",
      "object at location 218, 402, 179, 384\n",
      "object at location 238, 417, 298, 416\n",
      "object at location 116, 419, 60, 386\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Detect Objects - remote =====\")\n",
    "# Get URL image with different objects\n",
    "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "# Call API with URL\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e485cc7",
   "metadata": {},
   "source": [
    "## ローカルファイルに対応させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb165f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - local =====\n",
      "Detecting objects in local image:\n",
      "object at location 871, 1204, 258, 779\n",
      "object at location 423, 1086, 829, 1257\n",
      "object at location 1258, 1746, 752, 1291\n",
      "object at location 30, 1616, 177, 1434\n"
     ]
    }
   ],
   "source": [
    "local_image_path = 'img/sample01.jpg'\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "print(\"===== Detect Objects - local =====\")\n",
    "\n",
    "detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "\n",
    "print(\"Detecting objects in local image:\")\n",
    "if len(detect_objects_results.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3711309",
   "metadata": {},
   "source": [
    "## タグ取得（ローカル関数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a44412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    tags_result = computervision_client.tag_image_in_stream(local_image)\n",
    "    tags = tags_result.tags\n",
    "    tags_name = []\n",
    "    for tag in tags:\n",
    "        tags_name.append(tag.name)\n",
    "    \n",
    "    return tags_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "836de481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tableware',\n",
       " 'food',\n",
       " 'baked goods',\n",
       " 'plate',\n",
       " 'drink',\n",
       " 'coffee cup',\n",
       " 'dishware',\n",
       " 'saucer',\n",
       " 'snack',\n",
       " 'serveware',\n",
       " 'meal',\n",
       " 'mug',\n",
       " 'tea',\n",
       " 'fast food',\n",
       " 'breakfast',\n",
       " 'fork',\n",
       " 'dish',\n",
       " 'kitchen utensil',\n",
       " 'brunch',\n",
       " 'platter',\n",
       " 'dessert',\n",
       " 'cup',\n",
       " 'coffee',\n",
       " 'indoor',\n",
       " 'sitting',\n",
       " 'table']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'img/sample01.jpg'\n",
    "get_tags(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f919d",
   "metadata": {},
   "source": [
    "## 位置取得（ローカル関数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7feff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(filepath):\n",
    "    local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "    detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "    objects = detect_objects_results.objects\n",
    "    \n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee0548ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x14b363c9e20>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x14b363c9910>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x14b363c94c0>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x14b363c9c10>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'img/sample01.jpg'\n",
    "detect_objects(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60ea92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
